C:\Users\凝雨\AppData\Local\Programs\Python\Python39\python.exe C:/bingxingLab4/test1/main.py
batch_size: 64, D_in: 784, D_out: 10
0.0% iter: 0, loss: 3.1436930623393065
0.5% iter: 100, loss: 0.7861432509884254
1.0% iter: 200, loss: 0.4130124490767322
1.5% iter: 300, loss: 0.30455622761781537
2.0% iter: 400, loss: 0.35259466870633693
2.5% iter: 500, loss: 0.2969054194110793
3.0% iter: 600, loss: 0.1401259914425016
3.5% iter: 700, loss: 0.3164700183982488
4.0% iter: 800, loss: 0.10150974273224772
4.5% iter: 900, loss: 0.1743642030094374
5.0% iter: 1000, loss: 0.12559210133914336
5.5% iter: 1100, loss: 0.39386533348545205
6.0% iter: 1200, loss: 0.22789421409442895
6.5% iter: 1300, loss: 0.09276984841217863
7.0% iter: 1400, loss: 0.11523198915386665
7.5% iter: 1500, loss: 0.06405262609491823
8.0% iter: 1600, loss: 0.15878845956281273
8.5% iter: 1700, loss: 0.2634061603129151
9.0% iter: 1800, loss: 0.07491950028948663
9.5% iter: 1900, loss: 0.215316724336371
10.0% iter: 2000, loss: 0.05953397092005882
10.5% iter: 2100, loss: 0.17152187276925396
11.0% iter: 2200, loss: 0.08422490560215776
11.5% iter: 2300, loss: 0.19424597791364942
12.0% iter: 2400, loss: 0.11119793913831692
12.5% iter: 2500, loss: 0.13431835942638493
13.0% iter: 2600, loss: 0.07369169680499935
13.5% iter: 2700, loss: 0.17385571530658733
14.0% iter: 2800, loss: 0.12825177666152932
14.5% iter: 2900, loss: 0.04402446042806362
15.0% iter: 3000, loss: 0.08443635536714396
15.5% iter: 3100, loss: 0.03468583758361823
16.0% iter: 3200, loss: 0.08054332555068251
16.5% iter: 3300, loss: 0.11286350076888217
17.0% iter: 3400, loss: 0.10078298274082977
17.5% iter: 3500, loss: 0.09606702589851651
18.0% iter: 3600, loss: 0.12102086121990849
18.5% iter: 3700, loss: 0.07373419645554599
19.0% iter: 3800, loss: 0.06134981960397084
19.5% iter: 3900, loss: 0.03284182946999624
20.0% iter: 4000, loss: 0.08964179917058687
20.5% iter: 4100, loss: 0.0568642760213414
21.0% iter: 4200, loss: 0.03524530469720843
21.5% iter: 4300, loss: 0.07689819260421447
22.0% iter: 4400, loss: 0.056353820247793264
22.5% iter: 4500, loss: 0.10661120384780545
23.0% iter: 4600, loss: 0.02058137695011829
23.5% iter: 4700, loss: 0.1197451747331735
24.0% iter: 4800, loss: 0.14900967264975945
24.5% iter: 4900, loss: 0.01790837506293181
25.0% iter: 5000, loss: 0.09605730223105932
25.5% iter: 5100, loss: 0.05107465871602275
26.0% iter: 5200, loss: 0.22953191725844396
26.5% iter: 5300, loss: 0.03261309946317697
27.0% iter: 5400, loss: 0.14723816315815336
27.5% iter: 5500, loss: 0.04214771316241669
28.0% iter: 5600, loss: 0.019395365570219553
28.5% iter: 5700, loss: 0.02268405281790648
29.0% iter: 5800, loss: 0.04518921788582109
29.5% iter: 5900, loss: 0.0702336702714814
30.0% iter: 6000, loss: 0.0284248416610845
30.5% iter: 6100, loss: 0.03558512123882179
31.0% iter: 6200, loss: 0.0912189240571664
31.5% iter: 6300, loss: 0.046594380218422264
32.0% iter: 6400, loss: 0.09885438781520484
32.5% iter: 6500, loss: 0.04746228183324306
33.0% iter: 6600, loss: 0.03446555173528666
33.5% iter: 6700, loss: 0.03560486522169616
34.0% iter: 6800, loss: 0.03423605748277884
34.5% iter: 6900, loss: 0.02817253596935378
35.0% iter: 7000, loss: 0.03290283286308836
35.5% iter: 7100, loss: 0.038620900114602306
36.0% iter: 7200, loss: 0.025216492693571017
36.5% iter: 7300, loss: 0.01592573357975615
37.0% iter: 7400, loss: 0.044695881589594436
37.5% iter: 7500, loss: 0.0115386471671694
38.0% iter: 7600, loss: 0.06769858931383757
38.5% iter: 7700, loss: 0.012584710124342327
39.0% iter: 7800, loss: 0.03325293368571488
39.5% iter: 7900, loss: 0.1289566771184772
40.0% iter: 8000, loss: 0.06176103696730988
40.5% iter: 8100, loss: 0.011232184341808072
41.0% iter: 8200, loss: 0.022822504202674572
41.5% iter: 8300, loss: 0.0158989527053093
42.0% iter: 8400, loss: 0.011581355867101505
42.5% iter: 8500, loss: 0.011076829033039704
43.0% iter: 8600, loss: 0.03160248604933721
43.5% iter: 8700, loss: 0.020704145498108784
44.0% iter: 8800, loss: 0.023342949994206448
44.5% iter: 8900, loss: 0.037068271683141814
45.0% iter: 9000, loss: 0.08290576435545888
45.5% iter: 9100, loss: 0.013130495291144625
46.0% iter: 9200, loss: 0.007609826607517274
46.5% iter: 9300, loss: 0.05325640663811437
47.0% iter: 9400, loss: 0.02408365713505181
47.5% iter: 9500, loss: 0.006818734437217397
48.0% iter: 9600, loss: 0.03197301330537817
48.5% iter: 9700, loss: 0.03426194592502533
49.0% iter: 9800, loss: 0.010214073151121774
49.5% iter: 9900, loss: 0.0294021759291077
50.0% iter: 10000, loss: 0.02510310252966231
50.5% iter: 10100, loss: 0.014503287453155926
51.0% iter: 10200, loss: 0.02970538860700194
51.5% iter: 10300, loss: 0.004340963238720284
52.0% iter: 10400, loss: 0.01384105469589055
52.5% iter: 10500, loss: 0.0584835784125225
53.0% iter: 10600, loss: 0.019664879915413165
53.5% iter: 10700, loss: 0.03697055819883387
54.0% iter: 10800, loss: 0.024885110321456003
54.5% iter: 10900, loss: 0.007803228338689328
55.0% iter: 11000, loss: 0.027511122204942465
55.5% iter: 11100, loss: 0.017584769669321553
56.0% iter: 11200, loss: 0.0540800130679141
56.5% iter: 11300, loss: 0.008477246377495883
57.0% iter: 11400, loss: 0.010994334010052514
57.5% iter: 11500, loss: 0.005310018584582875
58.0% iter: 11600, loss: 0.04143959165859713
58.5% iter: 11700, loss: 0.029796225619525205
59.0% iter: 11800, loss: 0.008948139213123003
59.5% iter: 11900, loss: 0.005702424799982667
60.0% iter: 12000, loss: 0.004633002832811065
60.5% iter: 12100, loss: 0.03303500730982835
61.0% iter: 12200, loss: 0.022407891961287046
61.5% iter: 12300, loss: 0.04184869988192064
62.0% iter: 12400, loss: 0.014420169301329987
62.5% iter: 12500, loss: 0.016160477389892677
63.0% iter: 12600, loss: 0.006435574908401135
63.5% iter: 12700, loss: 0.04258202831055545
64.0% iter: 12800, loss: 0.06738953351538499
64.5% iter: 12900, loss: 0.014018961592260725
65.0% iter: 13000, loss: 0.006571628037444132
65.5% iter: 13100, loss: 0.0035028587484650896
66.0% iter: 13200, loss: 0.0034737776643313447
66.5% iter: 13300, loss: 0.003539145731647294
67.0% iter: 13400, loss: 0.005068891124092352
67.5% iter: 13500, loss: 0.019512915676139206
68.0% iter: 13600, loss: 0.006932745229154497
68.5% iter: 13700, loss: 0.008121005032576487
69.0% iter: 13800, loss: 0.010029739590209802
69.5% iter: 13900, loss: 0.001100092661720224
70.0% iter: 14000, loss: 0.003251984648164345
70.5% iter: 14100, loss: 0.008225472902858617
71.0% iter: 14200, loss: 0.028323378033596386
71.5% iter: 14300, loss: 0.0017668601263884935
72.0% iter: 14400, loss: 0.006214857596246817
72.5% iter: 14500, loss: 0.061018193333317004
73.0% iter: 14600, loss: 0.014588019449780523
73.5% iter: 14700, loss: 0.009397457726493913
74.0% iter: 14800, loss: 0.021255113577993864
74.5% iter: 14900, loss: 0.002494273450432152
75.0% iter: 15000, loss: 0.014534595364529489
75.5% iter: 15100, loss: 0.0192452105646114
76.0% iter: 15200, loss: 0.00618184748719827
76.5% iter: 15300, loss: 0.008883302622740495
77.0% iter: 15400, loss: 0.006251279751673019
77.5% iter: 15500, loss: 0.004932185479361165
78.0% iter: 15600, loss: 0.01981982031296261
78.5% iter: 15700, loss: 0.03575649029629458
79.0% iter: 15800, loss: 0.026740982028391303
79.5% iter: 15900, loss: 0.030098585581229315
80.0% iter: 16000, loss: 0.0019583841992203348
80.5% iter: 16100, loss: 0.024739300407907564
81.0% iter: 16200, loss: 0.016313579630366195
81.5% iter: 16300, loss: 0.004090217523336232
82.0% iter: 16400, loss: 0.00795552523894314
82.5% iter: 16500, loss: 0.00596245615993009
83.0% iter: 16600, loss: 0.026166046822032867
83.5% iter: 16700, loss: 0.00446532151626617
84.0% iter: 16800, loss: 0.003987195099134407
84.5% iter: 16900, loss: 0.01968458106803299
85.0% iter: 17000, loss: 0.009579465357247534
85.5% iter: 17100, loss: 0.008666507214452597
86.0% iter: 17200, loss: 0.011227447538910591
86.5% iter: 17300, loss: 0.006550402270173125
87.0% iter: 17400, loss: 0.0038854839234801182
87.5% iter: 17500, loss: 0.010263432227005775
88.0% iter: 17600, loss: 0.00604504692292885
88.5% iter: 17700, loss: 0.014061231900749468
89.0% iter: 17800, loss: 0.0001295297232616072
89.5% iter: 17900, loss: 0.006387568218961131
90.0% iter: 18000, loss: 0.0036870164450572215
90.5% iter: 18100, loss: 0.01846496695635743
91.0% iter: 18200, loss: 0.0036081359164506373
91.5% iter: 18300, loss: 0.0020575975390195967
92.0% iter: 18400, loss: 0.014339016479925519
92.5% iter: 18500, loss: 0.0006997212713451826
93.0% iter: 18600, loss: 0.00924007197272136
93.5% iter: 18700, loss: 0.005877055453085017
94.0% iter: 18800, loss: 0.0013738277140541212
94.5% iter: 18900, loss: 0.002851485002312357
95.0% iter: 19000, loss: 0.006991129148879927
95.5% iter: 19100, loss: 0.0016976097786550312
96.0% iter: 19200, loss: 0.0028496542989607334
96.5% iter: 19300, loss: 0.016939984709687612
97.0% iter: 19400, loss: 0.001282440790517721
97.5% iter: 19500, loss: 0.009322706479328972
98.0% iter: 19600, loss: 0.00330213423011231
98.5% iter: 19700, loss: 0.008323898589869412
99.0% iter: 19800, loss: 0.006180728099093682
99.5% iter: 19900, loss: 0.006489142132216091
TRAIN--> Correct: 59952 out of 60000, acc=0.9992
TEST--> Correct: 9801 out of 10000, acc=0.9801

进程已结束,退出代码0
